{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data from a File\n",
    "In the previous tutorial we graphed arrays of data, where we manually or mathematically filled the arrays. In some cases, we collect data into a local file and then later want to import that data into a Jupyter notebook. \n",
    "\n",
    "In this tutorial, we will learn to import data from a file using a library called `pandas`. We will see how to load files in four different ways.\n",
    "\n",
    "1. Read local files on your computer\n",
    "    * Read a delimited file called comma-separated values (.csv file)\n",
    "    * Read an Excel file (.xlsx)\n",
    "2. Read files from the web (url)\n",
    "3. Upload a file using Google's Colaboratory\n",
    "\n",
    "The first two methods work for a locally installed version of Jupyter such as Anaconda. The second and third methods work for the web-based Jupyter that is run by Google (https://colab.research.google.com/)\n",
    "\n",
    "## Filetypes\n",
    "### Comma-Separated Values (csv)\n",
    "In data collection and analysis, we are often confronted with files of different types. A common file output from a scientific instrument is a tab or comma-separated lists of data. We will look at the comma-separated variety. In a csv file, there may be as many columns as you wish that are all separated by commas. For example, a file might look like the following.\n",
    "\n",
    "Voltage,Current\n",
    "\n",
    "1.00,5.01\n",
    "\n",
    "2.00,10.10\n",
    "\n",
    "3.00,14.93\n",
    "\n",
    "4.00,20.27\n",
    "\n",
    "5.00,24.98\n",
    "\n",
    "This data can be downloaded from https://github.com/troymessina/ModernPhysics/blob/master/data/example.csv. Right-click and save this file to the same folder where this Jupyter notebook is saved. You may open it to see that it looks like above.\n",
    "\n",
    "## Pandas\n",
    "Pandas is a very powerful data handling library. We will use only very few of its capabilities. To import Pandas, use the following statement. This will make Pandas functionality available through `pd.*` syntax.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Local File\n",
    "Once you have imported the Pandas library, we can load the data into what is called a dataframe. A dataframe can handle many different structures of data. We will focus on numerical data with titles for each different list or array of data. To load a csv file into a dataframe use the following command.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('example.csv')\n",
    "```\n",
    "\n",
    "It's a good idea to use more meaningful dataframe names than `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a dataframe named `df`. In it are two columns titled \"Voltage\" and \"Current\". You can imagine something like the following table, where the first column is the row index starting with zero and the first row is the the title of each column. These first row and column are used for indexing the dataframe similar to how we indexed the `numpy` arrays in a previous exercise.\n",
    "\n",
    "|| Voltage  | Current |\n",
    "|---|---|---|\n",
    "| 0  | 1.00 | 5.01  |\n",
    "| 1  | 2.00 | 10.10  |\n",
    "| 2  | 3.00 | 14.93  |\n",
    "| 3  | 4.00 | 20.27  |\n",
    "| 4  | 5.00 | 24.98  |\n",
    "\n",
    "You can see the dataframe by printing it\n",
    "\n",
    "```python\n",
    "df.head()\n",
    "```\n",
    "\n",
    "You can also get a list of column names\n",
    "\n",
    "```python\n",
    "# iterating the columns \n",
    "for col in df.columns: \n",
    "    print(col) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Data\n",
    "Once data is loaded, it can be plotted using `matplotlib`. The beautiful thing about `pandas` is that we can reference the arrays by name. For example, importing `matplotlib` and plotting current vs. voltage might look like the following.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df['Voltage'], df['Current'], 'rs', label='Data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('Current (A)')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a File from URL\n",
    "We can load files from the web as long as we have a URL to the file. This can be useful if we are using Google's Colaboratory instead of an Jupyter installation on our computer. It can also be useful if you store data somewhere like GitHub (https://github.com/), which is a website for keeping up with computer coding projects. It's free!\n",
    "\n",
    "Suppose we want to load the file you just download, but without downloading it. You could do the following.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/troymessina/ModernPhysics/master/data/example.csv')\n",
    "```\n",
    "\n",
    "Notice, I had to go to GitHub and get a \"raw\" address to the file. It is always a good idea to check that it loaded by running the `head` command.\n",
    "\n",
    "```python\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from an Excel File\n",
    "This process is virtually the same as the csv file, except Excel files can store much more data using separate sheets. We can load individual sheets into separate dataframes. Right click and save the target Excel file in the following link to the same directory where this Jupyter notebook is saved. Open the Excel file and see that it has two sheets of data. To load the Excel file by sheet, one would use a command like the following.\n",
    "\n",
    "```python\n",
    "df = pd.read_excel('filename.xlsx', 'sheet name', index_col=None, na_values=['NA'])\n",
    "```\n",
    "\n",
    "The flag `index_col` tells Pandas that there is not a beginning column in the file that indexes the rows. The `na_values` tells Pandas how to deal with Excel cells that are Not A Number (NAN). Try loading each sheet into two different dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Excel Data\n",
    "Try plotting the Excel data with both sheets' data on the same graph with different marker colors and shapes. Do not use a connecting line between the markers. Label the axes. Label the data based on the sheet names, and be sure to show a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colaboratory\n",
    "This method ONLY works in the web-based Google Colaboratory. It will not work in a locally installed Jupyter environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code will create a pop-up so you can search for a local file to upload. Once uploaded you can use the method 1 that were used for local files. For example, if you upload a file named `filename.csv`, you would use pandas in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "df = pd.read_csv(io.StringIO(uploaded['filename.csv'].decode('utf-8')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
